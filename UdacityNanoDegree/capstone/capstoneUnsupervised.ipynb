{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\miska\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\miska\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\miska\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('sentiwordnet')\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For unsupervised learning we will be using the same tokens that has been created for supervised learning part. Before they were saved in txt file, so now we have to load them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens_v2.txt\", \"rb\") as fp:   # Unpickling\n",
    "     X_processed = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0        1.0\n",
       "1        1.0\n",
       "2        0.0\n",
       "3        1.0\n",
       "4        0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('y_v2.csv', sep=';', header=None)\n",
    "y = y.drop(0, axis=1)\n",
    "y = y.rename({1: 'sentiment'}, axis=1)\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part sentiwordnet dictionary will be used. And example of its usage below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "happiness = swn.senti_synset('happy.a.03')\n",
    "print(happiness.neg_score())\n",
    "print(happiness.pos_score())\n",
    "print(happiness.obj_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the example we could see that to work with it thru nltk package for each word we need to pass a POS tag (part-of-the-speech). To identify this - we will be using pos_tag function from nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('happy', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "test = nltk.pos_tag(nltk.word_tokenize('happy'))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where \"JJ\"stands for adjective.\n",
    "\n",
    "This is a small issue, as sentiwordnet works with a bit different format of POS. For this we need to build a fucntion which will convert it to the workable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(tagged_token):\n",
    "    token = tagged_token[0]\n",
    "    if token[1].startswith('NN'):\n",
    "        tag = 'n'\n",
    "    elif token[1].startswith('JJ'):\n",
    "        tag = 'a'\n",
    "    elif token[1].startswith('V'):\n",
    "        tag = 'v'\n",
    "    elif token[1].startswith('R'):\n",
    "        tag = 'r'\n",
    "    else:\n",
    "        tag = ''    \n",
    "    return (token[0], tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "token, tag = convert_tag(nltk.pos_tag(nltk.word_tokenize('happy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "print(token)\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using senti_synsets we can get all the synonyms for the token, for instance for \"happy\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy = list(swn.senti_synsets(token, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('happy.a.01'),\n",
       " SentiSynset('felicitous.s.02'),\n",
       " SentiSynset('glad.s.02'),\n",
       " SentiSynset('happy.s.04')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can count an average of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625 0.0 0.4375\n"
     ]
    }
   ],
   "source": [
    "pos, neg, obj = 0., 0., 0.\n",
    "for h in happy:\n",
    "    pos += h.pos_score()\n",
    "    neg += h.neg_score()\n",
    "    obj += h.obj_score()\n",
    "pos = pos / len(happy)\n",
    "neg = neg / len(happy)\n",
    "obj = obj / len(happy)\n",
    "print(pos, neg, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a function for getting an average score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(token, tag):\n",
    "    synms = list(swn.senti_synsets(token, tag))\n",
    "    pos, neg, obj = 0., 0., 0.\n",
    "    for s in synms:\n",
    "        pos += s.pos_score()\n",
    "        neg += s.neg_score()\n",
    "        obj += s.obj_score()\n",
    "    if len(synms)>0:\n",
    "        pos = pos / len(synms)\n",
    "        neg = neg / len(synms)\n",
    "        obj = obj / len(synms)\n",
    "    return pos, neg, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy a\n"
     ]
    }
   ],
   "source": [
    "token, tag = convert_tag(nltk.pos_tag(nltk.word_tokenize('happy')))\n",
    "print(token, tag)\n",
    "pos, neg, obj = avg_score(token, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5625, 0.0, 0.4375)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos, neg, obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try one of the sentences, we will calculate a sum of positives, negatives and objectives scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'place', 'obviously', 'bank', 'famous', 'founder', 'guys', 'good', 'think', 'service', 'slow', 'care', 'provide', 'good', 'dining', 'experience', 'table', 'dirty', 'wait', 'clean', 'bartender', 'nice', 'pretty', 'quick', 'skip', 'year', 'want', 'shake', 'look', 'pretty', 'small', 'price']\n",
      "---------------------------\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_processed[0])\n",
    "print('---------------------------')\n",
    "print(y.loc[0, 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "\n",
      "--------------\n",
      "place\n",
      "n\n",
      "0.0078125 0.0078125 0.984375\n",
      "--------------\n",
      "obviously\n",
      "r\n",
      "0.5 0.0 0.5\n",
      "--------------\n",
      "bank\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "famous\n",
      "a\n",
      "0.375 0.0 0.625\n",
      "--------------\n",
      "founder\n",
      "n\n",
      "0.0 0.041666666666666664 0.9583333333333334\n",
      "--------------\n",
      "guys\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "good\n",
      "a\n",
      "0.6190476190476191 0.005952380952380952 0.375\n",
      "--------------\n",
      "think\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "service\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "slow\n",
      "v\n",
      "0.0 0.041666666666666664 0.9583333333333334\n",
      "--------------\n",
      "care\n",
      "n\n",
      "0.20833333333333334 0.20833333333333334 0.5833333333333334\n",
      "--------------\n",
      "provide\n",
      "n\n",
      "0.0 0.0 0.0\n",
      "--------------\n",
      "good\n",
      "a\n",
      "0.6190476190476191 0.005952380952380952 0.375\n",
      "--------------\n",
      "dining\n",
      "v\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "experience\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "table\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "dirty\n",
      "n\n",
      "0.0 0.0 0.0\n",
      "--------------\n",
      "wait\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "clean\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "bartender\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "nice\n",
      "a\n",
      "0.65 0.075 0.275\n",
      "--------------\n",
      "pretty\n",
      "r\n",
      "0.125 0.25 0.625\n",
      "--------------\n",
      "quick\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "skip\n",
      "n\n",
      "0.0 0.1875 0.8125\n",
      "--------------\n",
      "year\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "want\n",
      "n\n",
      "0.25 0.15625 0.59375\n",
      "--------------\n",
      "shake\n",
      "n\n",
      "0.0 0.0625 0.9375\n",
      "--------------\n",
      "look\n",
      "n\n",
      "0.03125 0.09375 0.875\n",
      "--------------\n",
      "pretty\n",
      "r\n",
      "0.125 0.25 0.625\n",
      "--------------\n",
      "small\n",
      "a\n",
      "0.0125 0.2625 0.725\n",
      "--------------\n",
      "price\n",
      "n\n",
      "0.08928571428571429 0.0 0.9107142857142857\n",
      "--------------\n",
      "positive: 3.6122767857142857\n",
      "negative: 1.6488839285714285\n",
      "objective: 23.738839285714285\n"
     ]
    }
   ],
   "source": [
    "test = X_processed[0]\n",
    "pos, neg, obj = 0., 0., 0.\n",
    "for t in test:\n",
    "    print(t)\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(t))\n",
    "    token, tag = convert_tag(tagged)\n",
    "    print(tag)\n",
    "    if tag != '':\n",
    "        pos_t, neg_t, obj_t = avg_score(token, tag)\n",
    "        print(pos_t, neg_t, obj_t)\n",
    "        pos += pos_t\n",
    "        neg += neg_t\n",
    "        obj += obj_t\n",
    "    else: \n",
    "        pass\n",
    "    print('--------------')\n",
    "print(f'positive: {pos}')\n",
    "print(f'negative: {neg}')\n",
    "print(f'objective: {obj}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result this sentence is more positive than negative, in fact it's neutral, so let's check that on positive and negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y.loc[:, 'sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 0., 1., 2., 0., 0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impressed\n",
      "a\n",
      "0.5 0.5 0.0\n",
      "--------------\n",
      "place\n",
      "n\n",
      "0.0078125 0.0078125 0.984375\n",
      "--------------\n",
      "today\n",
      "n\n",
      "0.0625 0.0 0.9375\n",
      "--------------\n",
      "come\n",
      "v\n",
      "0.03571428571428571 0.005952380952380952 0.9583333333333334\n",
      "--------------\n",
      "lunch\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "order\n",
      "n\n",
      "0.016666666666666666 0.0 0.9833333333333333\n",
      "--------------\n",
      "shrimp\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "combo\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "disappointed\n",
      "a\n",
      "0.0 0.5 0.5\n",
      "--------------\n",
      "look\n",
      "n\n",
      "0.03125 0.09375 0.875\n",
      "--------------\n",
      "like\n",
      "\n",
      "--------------\n",
      "frozen\n",
      "n\n",
      "0.0 0.0 0.0\n",
      "--------------\n",
      "shrimp\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "grocery\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "store\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "tasting\n",
      "v\n",
      "0.125 0.0625 0.8125\n",
      "--------------\n",
      "grease\n",
      "n\n",
      "0.0 0.0625 0.9375\n",
      "--------------\n",
      "french\n",
      "a\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "fry\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "weren\n",
      "n\n",
      "0.0 0.0 0.0\n",
      "--------------\n",
      "season\n",
      "n\n",
      "0.16666666666666666 0.0 0.8333333333333334\n",
      "--------------\n",
      "drink\n",
      "n\n",
      "0.05 0.0 0.95\n",
      "--------------\n",
      "luke\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "warm\n",
      "n\n",
      "0.0 0.0 0.0\n",
      "--------------\n",
      "pay\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "dollar\n",
      "n\n",
      "0.0 0.03125 0.96875\n",
      "--------------\n",
      "meal\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "waste\n",
      "n\n",
      "0.05 0.1 0.85\n",
      "--------------\n",
      "money\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "time\n",
      "n\n",
      "0.125 0.0 0.875\n",
      "--------------\n",
      "positive: 1.170610119047619\n",
      "negative: 1.363764880952381\n",
      "objective: 23.465625000000003\n"
     ]
    }
   ],
   "source": [
    "test = X_processed[2]\n",
    "pos, neg, obj = 0., 0., 0.\n",
    "for t in test:\n",
    "    print(t)\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(t))\n",
    "    token, tag = convert_tag(tagged)\n",
    "    print(tag)\n",
    "    if tag != '':\n",
    "        pos_t, neg_t, obj_t = avg_score(token, tag)\n",
    "        print(pos_t, neg_t, obj_t)\n",
    "        pos += pos_t\n",
    "        neg += neg_t\n",
    "        obj += obj_t\n",
    "    else: \n",
    "        pass\n",
    "    print('--------------')\n",
    "print(f'positive: {pos}')\n",
    "print(f'negative: {neg}')\n",
    "print(f'objective: {obj}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works on negative 1.17 < 1.363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "a\n",
      "0.3125 0.020833333333333332 0.6666666666666666\n",
      "--------------\n",
      "customer\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "service\n",
      "n\n",
      "0.0 0.0 1.0\n",
      "--------------\n",
      "thoroughly\n",
      "r\n",
      "0.3125 0.0 0.6875\n",
      "--------------\n",
      "explain\n",
      "n\n",
      "0.0 0.0 0.0\n",
      "--------------\n",
      "treatment\n",
      "n\n",
      "0.09375 0.125 0.78125\n",
      "--------------\n",
      "reasonably\n",
      "r\n",
      "0.25 0.125 0.625\n",
      "--------------\n",
      "price\n",
      "n\n",
      "0.08928571428571429 0.0 0.9107142857142857\n",
      "--------------\n",
      "positive: 1.0580357142857142\n",
      "negative: 0.27083333333333337\n",
      "objective: 5.671130952380952\n"
     ]
    }
   ],
   "source": [
    "test = X_processed[7]\n",
    "pos, neg, obj = 0., 0., 0.\n",
    "for t in test:\n",
    "    print(t)\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(t))\n",
    "    token, tag = convert_tag(tagged)\n",
    "    print(tag)\n",
    "    if tag != '':\n",
    "        pos_t, neg_t, obj_t = avg_score(token, tag)\n",
    "        print(pos_t, neg_t, obj_t)\n",
    "        pos += pos_t\n",
    "        neg += neg_t\n",
    "        obj += obj_t\n",
    "    else: \n",
    "        pass\n",
    "    print('--------------')\n",
    "print(f'positive: {pos}')\n",
    "print(f'negative: {neg}')\n",
    "print(f'objective: {obj}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works in this example as well: 1.05 > 0.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This examples also show that this method is very limited - we can't understand whether the comment was neutral. To proceed further we will only leave samples with positive or negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y != 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['impressed', 'place', 'today', 'come', 'lunch', 'order', 'shrimp', 'combo', 'disappointed', 'look', 'like', 'frozen', 'shrimp', 'grocery', 'store', 'tasting', 'grease', 'french', 'fry', 'weren', 'season', 'drink', 'luke', 'warm', 'pay', 'dollar', 'meal', 'waste', 'money', 'time']\n",
      "['locate', 'excalibur', 'floor', 'place', 'doesn', 'donut', 'fresh', 'super', 'small', 'good', 'disgrace']\n",
      "['taste', 'like', 'real', 'white', 'castle', 'find', 'jersey', 'know', 'harold', 'kumar', 'travel', 'movie', 'this', 'pretty', 'knock', 'real', 'white', 'castle', '-pron-', 'ketchup', 'burger', 'signature', 'white', 'castle', 'sweet', 'cherish', 'white', 'castle', 'restaurant', 'east', 'coast']\n",
      "['great', 'customer', 'service', 'thoroughly', 'explain', 'treatment', 'reasonably', 'price']\n",
      "['place', 'online', 'order', 'hour', 'waiting', 'update', 'phone', 'problem', 'then', 'try', 'call', 'multiple', 'time', 'hang', 'line', 'ring', 'time', 'terrible', 'customer', 'service']\n",
      "['smoothie', 'taste', 'great', 'service', 'unfriendly', '-pron-', 'charge', 'water', 'sure', 'illegal', 'state', 'arizona']\n"
     ]
    }
   ],
   "source": [
    "#finding all the indexes with True\n",
    "for i in np.where(mask[:10] == True)[0]: print(X_processed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without neutral\n",
    "X_ = []\n",
    "for i in np.where(mask == True)[0]:\n",
    "    X_.append(X_processed[i])\n",
    "y_ = y[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check how this library works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100002 100002\n"
     ]
    }
   ],
   "source": [
    "print(len(X_), len(y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we have 100002 samples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "scoring = []\n",
    "scoring_details = []\n",
    "for num, sentence in enumerate(X_):\n",
    "    if num % 1000 == 0.:\n",
    "        print(num)\n",
    "    pos, neg, obj = 0., 0., 0.\n",
    "    for t in sentence:\n",
    "        tagged = nltk.pos_tag(nltk.word_tokenize(t))\n",
    "        token, tag = convert_tag(tagged)\n",
    "        if tag != '':\n",
    "            pos_t, neg_t, obj_t = avg_score(token, tag)\n",
    "            pos += pos_t\n",
    "            neg += neg_t\n",
    "            obj += obj_t\n",
    "        else: \n",
    "            pass\n",
    "    scoring_details.append([pos, neg, obj])\n",
    "    if (pos-neg) < 0.:\n",
    "        scoring.append(0.)\n",
    "    else:\n",
    "        scoring.append(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupervised accuracy: 0.6768264634707306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f'unsupervised accuracy: {accuracy_score(y_, np.array(scoring))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking sentences where prediction is wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = []\n",
    "for i in range(len(y_)):\n",
    "    if y_[i] != scoring[i]:\n",
    "        wrong.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 7, 13, 14, 15, 19, 22, 28, 30]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5317505411255412, 1.0736494408369408, 22.39460001803752]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_details[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taste',\n",
       " 'like',\n",
       " 'real',\n",
       " 'white',\n",
       " 'castle',\n",
       " 'find',\n",
       " 'jersey',\n",
       " 'know',\n",
       " 'harold',\n",
       " 'kumar',\n",
       " 'travel',\n",
       " 'movie',\n",
       " 'this',\n",
       " 'pretty',\n",
       " 'knock',\n",
       " 'real',\n",
       " 'white',\n",
       " 'castle',\n",
       " '-pron-',\n",
       " 'ketchup',\n",
       " 'burger',\n",
       " 'signature',\n",
       " 'white',\n",
       " 'castle',\n",
       " 'sweet',\n",
       " 'cherish',\n",
       " 'white',\n",
       " 'castle',\n",
       " 'restaurant',\n",
       " 'east',\n",
       " 'coast']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(str(x) for x in X_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'taste like real white castle find jersey know harold kumar travel movie this pretty knock real white castle -pron- ketchup burger signature white castle sweet cherish white castle restaurant east coast'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste v\n",
      "--------------------------------------\n",
      "real a\n",
      "--------------------------------------\n",
      "white a\n",
      "--------------------------------------\n",
      "castle a\n",
      "--------------------------------------\n",
      "find v\n",
      "--------------------------------------\n",
      "jersey n\n",
      "--------------------------------------\n",
      "know v\n",
      "--------------------------------------\n",
      "harold n\n",
      "--------------------------------------\n",
      "kumar n\n",
      "--------------------------------------\n",
      "travel n\n",
      "--------------------------------------\n",
      "movie n\n",
      "--------------------------------------\n",
      "pretty r\n",
      "--------------------------------------\n",
      "knock v\n",
      "--------------------------------------\n",
      "real a\n",
      "--------------------------------------\n",
      "white a\n",
      "--------------------------------------\n",
      "castle a\n",
      "--------------------------------------\n",
      "ketchup n\n",
      "--------------------------------------\n",
      "burger n\n",
      "--------------------------------------\n",
      "signature n\n",
      "--------------------------------------\n",
      "white a\n",
      "--------------------------------------\n",
      "castle a\n",
      "--------------------------------------\n",
      "sweet a\n",
      "--------------------------------------\n",
      "cherish a\n",
      "--------------------------------------\n",
      "white a\n",
      "--------------------------------------\n",
      "castle a\n",
      "--------------------------------------\n",
      "restaurant n\n",
      "--------------------------------------\n",
      "east n\n",
      "--------------------------------------\n",
      "coast n\n",
      "--------------------------------------\n",
      "1.6436553030303032 1.0516256313131314\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "pos, neg, obj = 0., 0., 0.\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        continue\n",
    "    elif (token.pos_ == 'PUNCT') or (token.pos_ == 'ADP'):\n",
    "        continue\n",
    "    else:\n",
    "        if token.tag_.startswith('NN'):\n",
    "            tag = 'n'\n",
    "        elif token.tag_.startswith('JJ'):\n",
    "            tag = 'a'\n",
    "        elif token.tag_.startswith('V'):\n",
    "            tag = 'v'\n",
    "        elif token.tag_.startswith('R'):\n",
    "            tag = 'r'\n",
    "        else:\n",
    "            tag = ''\n",
    "        print(token.lemma_, tag)       \n",
    "        if tag != '':\n",
    "            pos_t, neg_t, obj_t = avg_score(token.lemma_, tag)\n",
    "            pos += pos_t\n",
    "            neg += neg_t\n",
    "            obj += obj_t\n",
    "    print('--------------------------------------')\n",
    "print(pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy is giving the same result for worng sentences, however, just to compare performance I will run it with spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_spacy = []\n",
    "scoring_det_spacy = []\n",
    "for sent in X_:\n",
    "    text = ' '.join(str(x) for x in sent)\n",
    "    doc = nlp(text)\n",
    "    pos, neg, obj = 0., 0., 0.\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        elif (token.pos_ == 'PUNCT') or (token.pos_ == 'ADP'):\n",
    "            continue\n",
    "        else:\n",
    "            if token.tag_.startswith('NN'):\n",
    "                tag = 'n'\n",
    "            elif token.tag_.startswith('JJ'):\n",
    "                tag = 'a'\n",
    "            elif token.tag_.startswith('V'):\n",
    "                tag = 'v'\n",
    "            elif token.tag_.startswith('R'):\n",
    "                tag = 'r'\n",
    "            else:\n",
    "                tag = ''     \n",
    "            if tag != '':\n",
    "                pos_t, neg_t, obj_t = avg_score(token.lemma_, tag)\n",
    "                pos += pos_t\n",
    "                neg += neg_t\n",
    "                obj += obj_t\n",
    "    scoring_det_spacy.append([pos, neg, obj])\n",
    "    if (pos - neg) < 0:\n",
    "        scoring_spacy.append(0.)\n",
    "    else:\n",
    "        scoring_spacy.append(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupervised spacy accuracy: 0.7164356712865743\n"
     ]
    }
   ],
   "source": [
    "print(f'unsupervised spacy accuracy: {accuracy_score(y_, np.array(scoring_spacy))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the overall result is better with Spacy usage.\n",
    "This could be compared with results of CNN, as we had three categories there, but this is a very good result for non-labeled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_sentiment(text):\n",
    "    doc = nlp(text)\n",
    "    pos, neg, obj = 0., 0., 0.\n",
    "    for token in doc:\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        elif (token.pos_ == 'PUNCT') or (token.pos_ == 'ADP'):\n",
    "            continue\n",
    "        else:\n",
    "            if token.tag_.startswith('NN'):\n",
    "                tag = 'n'\n",
    "            elif token.tag_.startswith('JJ'):\n",
    "                tag = 'a'\n",
    "            elif token.tag_.startswith('V'):\n",
    "                tag = 'v'\n",
    "            elif token.tag_.startswith('R'):\n",
    "                tag = 'r'\n",
    "            else:\n",
    "                tag = ''     \n",
    "            if tag != '':\n",
    "                pos_t, neg_t, obj_t = avg_score(token.lemma_, tag)\n",
    "                pos += pos_t\n",
    "                neg += neg_t\n",
    "                obj += obj_t\n",
    "    if pos > neg:\n",
    "        result = 'positive'\n",
    "    else:\n",
    "        result = 'negative'\n",
    "    return [result, pos, neg, obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 0.32053571428571426, 1.1406655844155844, 2.538798701298701]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negative\n",
    "un_sentiment('Real lost again. It is terrible, how they can play like this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 0.8317307692307692, 0.1971153846153846, 1.9711538461538463]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive\n",
    "un_sentiment('Wow, it was amazing movie. What do you think?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 0.5416666666666667, 0.11458333333333334, 1.34375]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neutral\n",
    "un_sentiment('what is it like to be rich?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 0.6715555555555556, 0.24233333333333335, 1.086111111111111]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negative\n",
    "un_sentiment('I am not quite sure that I liked it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 0.0, 0.5, 2.5]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive\n",
    "un_sentiment('I do not dislike cabin cruisers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
